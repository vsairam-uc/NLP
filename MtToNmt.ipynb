{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMk+KG1gqD3ZDWBN8aliPXa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsairam-uc/NLP/blob/main/MtToNmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Librarries used:\n",
        "\n",
        "googletrans: https://pypi.org/project/googletrans/\n",
        "\n",
        "goslate: https://pypi.org/project/goslate/"
      ],
      "metadata": {
        "id": "I50f6UhvCCGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KQSZ9bIHIu5t",
        "outputId": "c6ce5756-76f7-4e63-81e8-b9226fb56c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m297.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.7.4)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.7.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=96a9b86a1b4c9c998fff690290e8053065b2847299edecb3e83fcd5820a6b3b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.7.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Collecting goslate\n",
            "  Downloading goslate-1.5.4.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting futures (from goslate)\n",
            "  Downloading futures-3.0.5.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: goslate, futures\n",
            "  Building wheel for goslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for goslate: filename=goslate-1.5.4-py3-none-any.whl size=11577 sha256=af9d861a083ed8caa6c5a1481e9ed22ba3b184235c00fec78226e75fcf23406f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/30/e9/63b6de83667be2977ee793a146a2c80f8e588d5c0203b39dc9\n",
            "  Building wheel for futures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for futures: filename=futures-3.0.5-py3-none-any.whl size=14067 sha256=5612c2a3e7bb8e1b61d2f9f17fcefbb828f9140317519b4531d5e5cb03562ea2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/af/93/48739d464ba97d4cdc77c627d282f9794c8d276e42aaa92160\n",
            "Successfully built goslate futures\n",
            "Installing collected packages: futures, goslate\n",
            "Successfully installed futures-3.0.5 goslate-1.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "concurrent"
                ]
              },
              "id": "138d8fa1b23240ebbcd7f6b5948c258f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install goslate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "from goslate import Goslate\n",
        "import difflib"
      ],
      "metadata": {
        "id": "kK91HRXAKPK3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate to English using googletrans"
      ],
      "metadata": {
        "id": "XCAlLmH9KlZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_english(text):\n",
        "    translator = Translator()\n",
        "    return translator.translate(text, dest='en').text"
      ],
      "metadata": {
        "id": "L6ifPRGdKQVA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate to French using goslate"
      ],
      "metadata": {
        "id": "CQmwTeBvKqpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_french(text):\n",
        "    translator = Goslate()\n",
        "    return translator.translate(text,'fr')"
      ],
      "metadata": {
        "id": "rrsOQWlfKh3Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_text = 'From Wikipedia, the free encyclopedia, Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model.It is the dominant approach today and can produce translations that rival human translations when translating between high-resource languages under specific conditions. However, there still remain challenges, especially with languages where less high-quality data is available,and with domain shift between the data a system was trained on and the texts it is supposed to translate. NMT systems also tend to produce fairly literal translations'"
      ],
      "metadata": {
        "id": "NIUwRC1bKw7J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(original_text.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7zCA1EMLh0Z",
        "outputId": "e0cb2f80-8cca-4d18-e3ad-56dc5c9132c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_text = translate_to_french(original_text)"
      ],
      "metadata": {
        "id": "Vh3fhg9gLlT_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "BDcL-_vTL3J_",
        "outputId": "d6b6bab6-0cc0-461f-8feb-4b91b5457efc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"De Wikipedia, l'Encyclopédie libre, la traduction des machines neurales (NMT) est une approche de la traduction automatique qui utilise un réseau neuronal artificiel pour prédire la probabilité d'une séquence de mots, modélisant généralement des phrases entières dans un seul modèle intégré. C'est l'approche dominante Aujourd'hui et peut produire des traductions qui rivalisent avec les traductions humaines lors de la traduction entre les langues à haute ressource dans des conditions spécifiques. Cependant, il reste des défis, en particulier avec les langues où des données moins de haute qualité sont disponibles, et avec le décalage du domaine entre les données sur lesquelles un système a été formé et les textes qu'il est censé traduire.\\u200aLes systèmes NMT ont également tendance à produire des traductions assez littérales\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "back_to_english = translate_to_english(french_text)"
      ],
      "metadata": {
        "id": "2Pq40-pwL8gy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "back_to_english"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "CdQQv-ShEYxx",
        "outputId": "dea746e7-6897-44b4-bf0b-7c35fe779ce0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'From Wikipedia, free encyclopedia, translation of neural machines (NMT) is an approach to automatic translation which uses an artificial neural network to predict the probability of a sequence of words, generally modeling whole sentences in a single integrated model.This is the dominant approach today and can produce translations that compete with human translations during the translation between high resources languages \\u200b\\u200bunder specific conditions.However, there are still challenges, in particular with languages \\u200b\\u200bwhere less high quality data are available, and with the lag of the domain between the data on which a system has been formed and the texts it is supposed to translate.NMT systems also tend to produce fairly literal translations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff = difflib.unified_diff(original_text.split('.'), back_to_english.split('.'), lineterm='')\n",
        "print('\\n'.join(list(diff)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65z1ZYYjFfBD",
        "outputId": "ea767cce-a51c-4c55-c4af-e1db06b508cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- \n",
            "+++ \n",
            "@@ -1,4 +1,4 @@\n",
            "-From Wikipedia, the free encyclopedia, Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model\n",
            "-It is the dominant approach today and can produce translations that rival human translations when translating between high-resource languages under specific conditions\n",
            "- However, there still remain challenges, especially with languages where less high-quality data is available,and with domain shift between the data a system was trained on and the texts it is supposed to translate\n",
            "- NMT systems also tend to produce fairly literal translations\n",
            "+From Wikipedia, free encyclopedia, translation of neural machines (NMT) is an approach to automatic translation which uses an artificial neural network to predict the probability of a sequence of words, generally modeling whole sentences in a single integrated model\n",
            "+This is the dominant approach today and can produce translations that compete with human translations during the translation between high resources languages ​​under specific conditions\n",
            "+However, there are still challenges, in particular with languages ​​where less high quality data are available, and with the lag of the domain between the data on which a system has been formed and the texts it is supposed to translate\n",
            "+NMT systems also tend to produce fairly literal translations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "differ = difflib.Differ()\n",
        "diff = list(differ.compare(original_text.split('.'), back_to_english.split('.')))\n",
        "print('\\n'.join(list(diff)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlkuPaLQJ2Sz",
        "outputId": "74d8bd56-044d-49fd-a560-667f29c26d67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- From Wikipedia, the free encyclopedia, Neural machine translation (NMT) is an approach to machine translation that uses an artificial neural network to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model\n",
            "+ From Wikipedia, free encyclopedia, translation of neural machines (NMT) is an approach to automatic translation which uses an artificial neural network to predict the probability of a sequence of words, generally modeling whole sentences in a single integrated model\n",
            "- It is the dominant approach today and can produce translations that rival human translations when translating between high-resource languages under specific conditions\n",
            "? ^^                                                                  ^ ^^^                    ^  -           -             ^\n",
            "\n",
            "+ This is the dominant approach today and can produce translations that compete with human translations during the translation between high resources languages ​​under specific conditions\n",
            "? ^^^^                                                                  ^^^^^^^^^ ^^                    ^^^^^^^^            +              ^        +           ++\n",
            "\n",
            "-  However, there still remain challenges, especially with languages where less high-quality data is available,and with domain shift between the data a system was trained on and the texts it is supposed to translate\n",
            "+ However, there are still challenges, in particular with languages ​​where less high quality data are available, and with the lag of the domain between the data on which a system has been formed and the texts it is supposed to translate\n",
            "-  NMT systems also tend to produce fairly literal translations\n",
            "? -\n",
            "\n",
            "+ NMT systems also tend to produce fairly literal translations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('translation_diff.txt', 'w', encoding='utf-8') as f:\n",
        "#         f.write(\"Differences:\\n\" + '\\n'.join(list(diff)))"
      ],
      "metadata": {
        "id": "E31kF6uvK5pm"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}